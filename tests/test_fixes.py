#!/usr/bin/env python3
"""
Test script to verify TTS pipeline fixes.
"""

import sys
import logging
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def setup_logging():
    """Setup logging."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def test_metal_framework_resilience():
    """Test Metal framework error handling and fallback mechanisms."""
    print("\nğŸ”¬ Testing Metal Framework Resilience...")

    try:
        from utils.config import load_config
        from pipelines.tts_pipeline import MLXKokoroModel

        config = load_config()
        model = MLXKokoroModel(config.tts)

        print(f"âœ… MLX Model initialized with degradation level: {model.degradation_level}")
        print(f"âœ… Force sequential: {model.force_sequential}")
        print(f"âœ… Max retries: {model.max_retries}")

        # Test resource cleanup
        model._cleanup_metal_resources()
        print("âœ… Metal resource cleanup executed without errors")

        # Test mock synthesis fallback
        mock_audio = model._try_mock_synthesis("Test text", 1.0)
        print(f"âœ… Mock synthesis fallback works: {mock_audio.shape}")

        return True

    except Exception as e:
        print(f"âŒ Metal framework test failed: {e}")
        return False

def test_image_pipeline_paths():
    """Test image pipeline path handling."""
    print("\nğŸ–¼ï¸  Testing Image Pipeline Path Handling...")

    try:
        from utils.config import load_config
        from pipelines.image_pipeline import ImageDescriptionPipeline, GemmaVLMModel

        config = load_config()

        # Test Gemma model initialization (without actual connection)
        gemma_model = GemmaVLMModel("gemma-3n-e4b", "http://127.0.0.1:1234")
        print(f"âœ… Gemma model created: {gemma_model.model_name}")
        print(f"âœ… API endpoint: {gemma_model.api_endpoint}")

        # Test pipeline creation
        pipeline = ImageDescriptionPipeline(config.image_description)
        print("âœ… Image pipeline created successfully")

        # Test model info
        model_info = pipeline.get_model_info()
        print(f"âœ… Model info: {model_info['model_name']}")

        return True

    except Exception as e:
        print(f"âŒ Image pipeline test failed: {e}")
        return False

def test_configuration_integration():
    """Test that all configurations are properly integrated."""
    print("\nâš™ï¸  Testing Configuration Integration...")

    try:
        from utils.config import load_config

        config = load_config()

        # Verify TTS configuration
        print(f"âœ… TTS Model: {config.tts.model}")
        print(f"âœ… TTS Use MLX: {config.tts.use_mlx}")

        # Verify Image configuration
        print(f"âœ… Image Model: {config.image_description.model}")
        print(f"âœ… Image API URL: {config.image_description.api_url}")
        print(f"âœ… Image Enabled: {config.image_description.enabled}")

        # Verify other settings
        print(f"âœ… Max Description Length: {config.image_description.max_description_length}")
        print(f"âœ… Include Context: {config.image_description.include_context}")

        return True

    except Exception as e:
        print(f"âŒ Configuration test failed: {e}")
        return False

def test_pipeline_orchestration():
    """Test pipeline orchestration without running full processing."""
    print("\nğŸ¼ Testing Pipeline Orchestration...")

    try:
        from utils.config import load_config
        from pipelines.orchestrator import PipelineOrchestrator

        config = load_config()
        orchestrator = PipelineOrchestrator(config)

        # Test pipeline status
        status = orchestrator.get_pipeline_status()
        print("âœ… Pipeline Status:")
        for key, value in status.items():
            print(f"   {key}: {value}")

        # Test cleanup
        orchestrator.cleanup()
        print("âœ… Pipeline cleanup completed")

        return True

    except Exception as e:
        print(f"âŒ Pipeline orchestration test failed: {e}")
        return False

def main():
    """Run all tests."""
    setup_logging()

    print("ğŸš€ Starting TTS Pipeline Fix Tests")
    print("=" * 50)

    tests = [
        test_configuration_integration,
        test_metal_framework_resilience,
        test_image_pipeline_paths,
        test_pipeline_orchestration
    ]

    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"âŒ Test failed with exception: {e}")
            results.append(False)

    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results Summary:")

    passed = sum(results)
    total = len(results)

    for i, (test, result) in enumerate(zip(tests, results)):
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {i+1}. {test.__name__}: {status}")

    print(f"\nğŸ¯ Overall: {passed}/{total} tests passed")

    if passed == total:
        print("ğŸ‰ All tests passed! TTS pipeline fixes are working correctly.")
        return 0
    else:
        print("âš ï¸  Some tests failed. Please check the output above.")
        return 1

if __name__ == "__main__":
    sys.exit(main())